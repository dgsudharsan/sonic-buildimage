From f790ebb0a0ef558fa2a0ae5d776b69e555261eb0 Mon Sep 17 00:00:00 2001
From: Donald Sharp <sharpd@nvidia.com>
Date: Tue, 1 Oct 2024 14:31:08 -0400
Subject: [PATCH 1/5] lib: nexthop code should use uint16_t for nexthop
 counting

It's possible to specify via the cli and configure how many
nexthops that are allowed on the system.  If you happen to
have > 255 then things are about to get interesting otherwise.

Let's allow up to 65k nexthops (ha!)

Signed-off-by: Donald Sharp <sharpd@nvidia.com>
---
 lib/nexthop_group.c | 24 +++++++++++-------------
 lib/nexthop_group.h |  8 ++++----
 2 files changed, 15 insertions(+), 17 deletions(-)

diff --git a/lib/nexthop_group.c b/lib/nexthop_group.c
index 41fe64606b..179296dec5 100644
--- a/lib/nexthop_group.c
+++ b/lib/nexthop_group.c
@@ -82,10 +82,10 @@ static struct nexthop *nexthop_group_tail(const struct nexthop_group *nhg)
 	return nexthop;
 }
 
-uint8_t nexthop_group_nexthop_num(const struct nexthop_group *nhg)
+uint16_t nexthop_group_nexthop_num(const struct nexthop_group *nhg)
 {
 	struct nexthop *nhop;
-	uint8_t num = 0;
+	uint16_t num = 0;
 
 	for (ALL_NEXTHOPS_PTR(nhg, nhop))
 		num++;
@@ -93,10 +93,10 @@ uint8_t nexthop_group_nexthop_num(const struct nexthop_group *nhg)
 	return num;
 }
 
-uint8_t nexthop_group_nexthop_num_no_recurse(const struct nexthop_group *nhg)
+uint16_t nexthop_group_nexthop_num_no_recurse(const struct nexthop_group *nhg)
 {
 	struct nexthop *nhop;
-	uint8_t num = 0;
+	uint16_t num = 0;
 
 	for (nhop = nhg->nexthop; nhop; nhop = nhop->next)
 		num++;
@@ -104,10 +104,10 @@ uint8_t nexthop_group_nexthop_num_no_recurse(const struct nexthop_group *nhg)
 	return num;
 }
 
-uint8_t nexthop_group_active_nexthop_num(const struct nexthop_group *nhg)
+uint16_t nexthop_group_active_nexthop_num(const struct nexthop_group *nhg)
 {
 	struct nexthop *nhop;
-	uint8_t num = 0;
+	uint16_t num = 0;
 
 	for (ALL_NEXTHOPS_PTR(nhg, nhop)) {
 		if (CHECK_FLAG(nhop->flags, NEXTHOP_FLAG_ACTIVE))
@@ -117,11 +117,11 @@ uint8_t nexthop_group_active_nexthop_num(const struct nexthop_group *nhg)
 	return num;
 }
 
-uint8_t
+uint16_t
 nexthop_group_active_nexthop_num_no_recurse(const struct nexthop_group *nhg)
 {
 	struct nexthop *nhop;
-	uint8_t num = 0;
+	uint16_t num = 0;
 
 	for (nhop = nhg->nexthop; nhop; nhop = nhop->next) {
 		if (CHECK_FLAG(nhop->flags, NEXTHOP_FLAG_ACTIVE))
@@ -197,11 +197,9 @@ static struct nexthop *nhg_nh_find(const struct nexthop_group *nhg,
 	return NULL;
 }
 
-static bool
-nexthop_group_equal_common(const struct nexthop_group *nhg1,
-			   const struct nexthop_group *nhg2,
-			   uint8_t (*nexthop_group_nexthop_num_func)(
-				   const struct nexthop_group *nhg))
+static bool nexthop_group_equal_common(
+	const struct nexthop_group *nhg1, const struct nexthop_group *nhg2,
+	uint16_t (*nexthop_group_nexthop_num_func)(const struct nexthop_group *nhg))
 {
 	if (nhg1 && !nhg2)
 		return false;
diff --git a/lib/nexthop_group.h b/lib/nexthop_group.h
index 0ea0b7c185..d41e298260 100644
--- a/lib/nexthop_group.h
+++ b/lib/nexthop_group.h
@@ -162,12 +162,12 @@ extern void nexthop_group_json_nexthop(json_object *j,
 				       const struct nexthop *nh);
 
 /* Return the number of nexthops in this nhg */
-extern uint8_t nexthop_group_nexthop_num(const struct nexthop_group *nhg);
-extern uint8_t
+extern uint16_t nexthop_group_nexthop_num(const struct nexthop_group *nhg);
+extern uint16_t
 nexthop_group_nexthop_num_no_recurse(const struct nexthop_group *nhg);
-extern uint8_t
+extern uint16_t
 nexthop_group_active_nexthop_num(const struct nexthop_group *nhg);
-extern uint8_t
+extern uint16_t
 nexthop_group_active_nexthop_num_no_recurse(const struct nexthop_group *nhg);
 
 #ifdef __cplusplus
-- 
2.43.2


From 7ae3e687a3cb0e29ef33368b6647b2d7c6e2ec2a Mon Sep 17 00:00:00 2001
From: Donald Sharp <sharpd@nvidia.com>
Date: Thu, 28 Sep 2023 12:27:31 -0400
Subject: [PATCH 2/5] zebra: Score weighted values of ecmp to a number between
 1-255

Currently underlying asics get into a bit of trouble when the
nexthop weight passed down varies wildly between the different
numbers.  Let's normalize the weight values between 1 and 255

Signed-off-by: Donald Sharp <sharpd@nvidia.com>
---
 zebra/zapi_msg.c | 38 ++++++++++++++++++++++++++++++++++++++
 1 file changed, 38 insertions(+)

diff --git a/zebra/zapi_msg.c b/zebra/zapi_msg.c
index c478f83795..c1179dfece 100644
--- a/zebra/zapi_msg.c
+++ b/zebra/zapi_msg.c
@@ -1714,10 +1714,14 @@ static bool zapi_read_nexthops(struct zserv *client, struct prefix *p,
 			       struct nexthop_group **png,
 			       struct nhg_backup_info **pbnhg)
 {
+	struct zapi_nexthop *znh;
 	struct nexthop_group *ng = NULL;
 	struct nhg_backup_info *bnhg = NULL;
 	uint16_t i;
 	struct nexthop *last_nh = NULL;
+	bool same_weight = true;
+	uint64_t max_weight = 0;
+	uint64_t tmp;
 
 	assert(!(png && pbnhg));
 
@@ -1732,6 +1736,40 @@ static bool zapi_read_nexthops(struct zserv *client, struct prefix *p,
 		bnhg = zebra_nhg_backup_alloc();
 	}
 
+	for (i = 0; i < nexthop_num; i++) {
+		znh = &nhops[i];
+
+		if (max_weight < znh->weight) {
+			if (i != 0 || znh->weight != 1)
+				same_weight = false;
+
+			max_weight = znh->weight;
+		}
+	}
+
+	/*
+	 * Let's convert the weights to a scaled value
+	 * between 1 and zrouter.nexthop_weight_scale_value
+	 * This is a simple application of a ratio:
+	 * scaled_weight/zrouter.nexthop_weight_scale_value = 
+         * weight/max_weight
+	 * This translates to:
+	 * scaled_weight = weight * zrouter.nexthop_weight_scale_value
+	 *                 -------------------------------------------
+	 *                           max_weight
+	 *
+	 * This same formula is applied to both the nexthops
+	 * and the backup nexthops
+	 */
+	if (!same_weight) {
+		for (i = 0; i < nexthop_num; i++) {
+			znh = &nhops[i];
+
+			tmp = (uint64_t)znh->weight * 255;
+			znh->weight = MAX(1, ((uint32_t)(tmp / max_weight)));
+		}
+	}
+
 	/*
 	 * TBD should _all_ of the nexthop add operations use
 	 * api_nh->vrf_id instead of re->vrf_id ? I only changed
-- 
2.43.2


From 52749247ec94532955ce16720bc04c79d339ee5f Mon Sep 17 00:00:00 2001
From: Donald Sharp <sharpd@nvidia.com>
Date: Thu, 28 Sep 2023 12:44:31 -0400
Subject: [PATCH 3/5] zebra: Make ucmp scale value owned by zrouter

The weight scale value might be useful to have it
change it's behavior at a later time or controlled
by something depending on how FRR is compiled/ran.
Let's start that process

Signed-off-by: Donald Sharp <sharpd@nvidia.com>
---
 zebra/zapi_msg.c     | 3 ++-
 zebra/zebra_router.c | 2 ++
 zebra/zebra_router.h | 2 ++
 3 files changed, 6 insertions(+), 1 deletion(-)

diff --git a/zebra/zapi_msg.c b/zebra/zapi_msg.c
index c1179dfece..f199004552 100644
--- a/zebra/zapi_msg.c
+++ b/zebra/zapi_msg.c
@@ -1765,7 +1765,8 @@ static bool zapi_read_nexthops(struct zserv *client, struct prefix *p,
 		for (i = 0; i < nexthop_num; i++) {
 			znh = &nhops[i];
 
-			tmp = (uint64_t)znh->weight * 255;
+			tmp = (uint64_t)znh->weight *
+			      zrouter.nexthop_weight_scale_value;
 			znh->weight = MAX(1, ((uint32_t)(tmp / max_weight)));
 		}
 	}
diff --git a/zebra/zebra_router.c b/zebra/zebra_router.c
index 12689804ea..707c4e1f62 100644
--- a/zebra/zebra_router.c
+++ b/zebra/zebra_router.c
@@ -343,6 +343,8 @@ void zebra_router_init(bool asic_offload, bool notify_on_ack)
 #endif
 	zrouter.asic_notification_nexthop_control = false;
 
+	zrouter.nexthop_weight_scale_value = 255;
+
 #ifdef HAVE_SCRIPTING
 	zebra_script_init();
 #endif
diff --git a/zebra/zebra_router.h b/zebra/zebra_router.h
index 61bde4ac2a..1eb4a6ca32 100644
--- a/zebra/zebra_router.h
+++ b/zebra/zebra_router.h
@@ -246,6 +246,8 @@ struct zebra_router {
 	bool allow_delete;
 
 	uint8_t protodown_r_bit;
+
+	uint64_t nexthop_weight_scale_value;
 };
 
 #define GRACEFUL_RESTART_TIME 60
-- 
2.43.2


From c0729979a55a0ad11823d555627bc86bd7b85211 Mon Sep 17 00:00:00 2001
From: Donald Sharp <sharpd@nvidia.com>
Date: Fri, 29 Sep 2023 15:17:14 -0400
Subject: [PATCH 4/5] bgpd: Just pass down the Bandwidth unmodified so that
 Zebra can use it

Instead of scaling the bandwith to something between 1 and 100, just
send down the bandwidth Available for the link.

Signed-off-by: Donald Sharp <sharpd@nvidia.com>
---
 bgpd/bgp_zebra.c | 12 +++---------
 1 file changed, 3 insertions(+), 9 deletions(-)

diff --git a/bgpd/bgp_zebra.c b/bgpd/bgp_zebra.c
index 038d328a60..6c842deb6f 100644
--- a/bgpd/bgp_zebra.c
+++ b/bgpd/bgp_zebra.c
@@ -1270,24 +1270,18 @@ static bool update_ipv6nh_for_route_install(int nh_othervrf, struct bgp *nh_bgp,
 static bool bgp_zebra_use_nhop_weighted(struct bgp *bgp, struct attr *attr,
 					uint64_t tot_bw, uint32_t *nh_weight)
 {
-	uint32_t bw;
-	uint64_t tmp;
-
-	bw = attr->link_bw;
 	/* zero link-bandwidth and link-bandwidth not present are treated
 	 * as the same situation.
 	 */
-	if (!bw) {
+	if (!attr->link_bw) {
 		/* the only situations should be if we're either told
 		 * to skip or use default weight.
 		 */
 		if (bgp->lb_handling == BGP_LINK_BW_SKIP_MISSING)
 			return false;
 		*nh_weight = BGP_ZEBRA_DEFAULT_NHOP_WEIGHT;
-	} else {
-		tmp = (uint64_t)bw * 100;
-		*nh_weight = ((uint32_t)(tmp / tot_bw));
-	}
+	} else
+		*nh_weight = attr->link_bw;
 
 	return true;
 }
-- 
2.43.2


From b4bb4a56f35dc85ecea30e6c3ea39a5b37a1df26 Mon Sep 17 00:00:00 2001
From: Donald Sharp <sharpd@nvidia.com>
Date: Fri, 29 Sep 2023 15:19:54 -0400
Subject: [PATCH 5/5] bgpd: Remove unused cumulative bandwidth variable

Signed-off-by: Donald Sharp <sharpd@nvidia.com>
---
 bgpd/bgp_zebra.c | 7 ++-----
 1 file changed, 2 insertions(+), 5 deletions(-)

diff --git a/bgpd/bgp_zebra.c b/bgpd/bgp_zebra.c
index 6c842deb6f..52b05a4af7 100644
--- a/bgpd/bgp_zebra.c
+++ b/bgpd/bgp_zebra.c
@@ -1268,7 +1268,7 @@ static bool update_ipv6nh_for_route_install(int nh_othervrf, struct bgp *nh_bgp,
 }
 
 static bool bgp_zebra_use_nhop_weighted(struct bgp *bgp, struct attr *attr,
-					uint64_t tot_bw, uint32_t *nh_weight)
+					uint32_t *nh_weight)
 {
 	/* zero link-bandwidth and link-bandwidth not present are treated
 	 * as the same situation.
@@ -1309,7 +1309,6 @@ bgp_zebra_announce_actual(struct bgp_dest *dest, struct bgp_path_info *info,
 	int nh_othervrf = 0;
 	bool nh_updated = false;
 	bool do_wt_ecmp;
-	uint64_t cum_bw = 0;
 	uint32_t nhg_id = 0;
 	bool is_add;
 	uint32_t ttl = 0;
@@ -1375,8 +1374,6 @@ bgp_zebra_announce_actual(struct bgp_dest *dest, struct bgp_path_info *info,
 
 	/* Determine if we're doing weighted ECMP or not */
 	do_wt_ecmp = bgp_path_info_mpath_chkwtd(bgp, info);
-	if (do_wt_ecmp)
-		cum_bw = bgp_path_info_mpath_cumbw(info);
 
 	/* EVPN MAC-IP routes are installed with a L3 NHG id */
 	if (bgp_evpn_path_es_use_nhg(bgp, info, &nhg_id)) {
@@ -1415,7 +1412,7 @@ bgp_zebra_announce_actual(struct bgp_dest *dest, struct bgp_path_info *info,
 		 */
 		if (do_wt_ecmp) {
 			if (!bgp_zebra_use_nhop_weighted(bgp, mpinfo->attr,
-							 cum_bw, &nh_weight))
+							 &nh_weight))
 				continue;
 		}
 		api_nh = &api.nexthops[valid_nh_count];
-- 
2.43.2

